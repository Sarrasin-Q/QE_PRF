{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# Data Loading\n",
    "main_path = 'E:/PycharmProjects/EE448/ee448-project2-query-expansion/'\n",
    "\n",
    "doc_dict = dict()\n",
    "query_dict = dict()\n",
    "rele_dict = dict()\n",
    "# doc.txt\n",
    "with open(main_path+'doc.txt') as lines:\n",
    "    for line in lines:\n",
    "        id, text = line.strip().split('\\t')\n",
    "        doc_dict[id] = text\n",
    "# query.txt\n",
    "with open(main_path+'query.txt') as lines:\n",
    "    for line in lines:\n",
    "        id, text = line.strip().split('\\t')\n",
    "        query_dict[id] = text\n",
    "# rele.txt\n",
    "with open(main_path+'rele.txt') as lines:\n",
    "    for line in lines:\n",
    "        query_id, document_id, relevance_score = line.strip().split('\\t')\n",
    "        if rele_dict.get(query_id) == None:\n",
    "            rele_dict[query_id] = dict()\n",
    "        rele_dict[query_id][document_id] = relevance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calc bm25\n",
    "def example_list2dict(input):\n",
    "    output = dict()\n",
    "    for word in input.split():\n",
    "        if output.get(word) is None:\n",
    "            output[word] = 0\n",
    "        output[word] += 1\n",
    "    return output\n",
    "\n",
    "\n",
    "def cal_idf(doc_dict):\n",
    "    doc_num = len(doc_dict)\n",
    "    idf = dict()\n",
    "    for doc_id in doc_dict:\n",
    "        doc_text = list(set(doc_dict[doc_id].split()))\n",
    "        for word in doc_text:\n",
    "            if idf.get(word) is None:\n",
    "                idf[word] = 0\n",
    "            idf[word] += 1\n",
    "    for word in idf:\n",
    "        idf[word] = math.log((doc_num - idf[word] + 0.5) / (idf[word] + 0.5))\n",
    "    return idf\n",
    "\n",
    "\n",
    "def bm25(query, doc, idf, avg_doc_len=374):\n",
    "    k1 = 2.0\n",
    "    k2 = 1.0\n",
    "    b = 0.75\n",
    "    score = 0.0\n",
    "    for word in query:\n",
    "        if doc.get(word) == None:\n",
    "            continue\n",
    "        W_i = idf[word]\n",
    "        f_i = doc[word]\n",
    "        qf_i = query[word]\n",
    "        doc_len = sum(doc.values())\n",
    "        K = k1 * (1 - b + b * doc_len / avg_doc_len)\n",
    "        R1 = f_i * (k1 + 1) / (f_i + K)\n",
    "        R2 = qf_i * (k2 + 1) / (qf_i + k2)\n",
    "        R = R1 * R2\n",
    "        score += W_i * R\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_sim(query, corpus):\n",
    "    \"\"\"\n",
    "    Get  TF-IDF values between query and corpus\n",
    "\n",
    "    Args:\n",
    "        query (list/Series): query in the form of a nested list or pandas.Series\n",
    "        corpus (list): documents in the form of a nested list or pandas.Series\n",
    "     Returns:\n",
    "        sims: similarity scores\n",
    "    \"\"\"\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    \n",
    "    doc_vectors = [dictionary.doc2bow(text) for text in corpus]\n",
    "    \n",
    "    tfidf = models.TfidfModel(doc_vectors)\n",
    "    \n",
    "    tfidf_vectors = tfidf[doc_vectors]\n",
    "    \n",
    "    query_bow = dictionary.doc2bow(query)\n",
    "    \n",
    "    index = similarities.MatrixSimilarity(tfidf_vectors)\n",
    "    \n",
    "    sims = index[query_bow]\n",
    "    \n",
    "    return sims\n",
    "\n",
    "\n",
    "def top_tfidf(docs, n, n_gram=(1, 1)):\n",
    "    \"\"\"\n",
    "    Get top n terms with highest TF-IDF value\n",
    "    from some docs.\n",
    "\n",
    "    Args:\n",
    "        docs (list/Series): Text document in the form of a nested list or pandas.Series\n",
    "        n (int): Number of terms. To get all possible terms, put n=-1\n",
    "        n_gram (tuple): Range of n_gram, default (1,1)\n",
    "     Returns:\n",
    "        top_term_with_scores: returns top n terms with the highest TF-IDF values,\n",
    "        together with the TF-IDF values\n",
    "    \"\"\"\n",
    "    # initialize TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(ngram_range=n_gram)\n",
    "\n",
    "    # Fit vectorizer to the documents\n",
    "    vectorizer.fit(docs)\n",
    "\n",
    "    # Get TF-IDF values from the documents\n",
    "    transformed = vectorizer.transform(docs)\n",
    "\n",
    "    # Get the TF-IDF value for each word/vocabulary\n",
    "    scores = zip(vectorizer.get_feature_names(), np.asarray(transformed.sum(axis=0)).ravel())\n",
    "\n",
    "    # Sort terms based on highest TF-IDF value\n",
    "    top_term_with_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top n terms with the highest TF-IDF value\n",
    "    top_term = []\n",
    "    for item in top_term_with_scores[:n]:\n",
    "        top_term.append(item[0])\n",
    "    return top_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_freq(terms, doc, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        terms: str list\n",
    "        doc: str list\n",
    "        window_size: int\n",
    "    Returns:\n",
    "        count: int\n",
    "    \"\"\"\n",
    "    term_num = len(terms)\n",
    "    doc_len = len(doc)\n",
    "    count = 0\n",
    "    for index in range(0, doc_len - window_size + 1):\n",
    "        flag = True\n",
    "        for i in range(0, term_num):\n",
    "            if not (terms[i] in doc[index:index + window_size]):\n",
    "                flag = False\n",
    "        if flag:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def min_dist(termA, termB, doc):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        termA: str\n",
    "        termB: str\n",
    "        doc: str list\n",
    "    Returns:\n",
    "        min_dist: int\n",
    "    \"\"\"\n",
    "    minD = len(doc)\n",
    "    posA = posB = -1\n",
    "    for index in range(0, len(doc)):\n",
    "        if doc[index] == termA:\n",
    "            posA = index\n",
    "        elif doc[index] == termB:\n",
    "            posB = index\n",
    "        if posA > -1 and posB > -1 and minD > abs(posA - posB):\n",
    "            minD = abs(posA - posB)\n",
    "    return minD\n",
    "\n",
    "\n",
    "def ave_prec(rec, prec, use_07_metric=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        rec: recall list\n",
    "        prec: precision list\n",
    "    Returns:\n",
    "        ap: average precision\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# used for calc term's features and label\n",
    "def get_feature(term, query_id, doc_ids, releDoc_ids):\n",
    "    '''\n",
    "    Args:\n",
    "        term: str\n",
    "        query_id: str\n",
    "        doc_ids: str list\n",
    "        releDoc_ids: str list\n",
    "    Returns:\n",
    "        feature: float list (1x8)\n",
    "    '''\n",
    "    global query_dict, doc_dict\n",
    "    features = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    query = query_dict[query_id].split()\n",
    "\n",
    "    min_dist_all = []\n",
    "    term_fre_all = []\n",
    "    query_fre_all = []\n",
    "    Co_occur_fre_all = []\n",
    "    pair_occur_fre_all = []\n",
    "\n",
    "    min_dist_rele = []\n",
    "    term_fre_rele = []\n",
    "    query_fre_rele = []\n",
    "    Co_occur_fre_rele = []\n",
    "    pair_occur_fre_rele = []\n",
    "\n",
    "    for doc_id in doc_ids:\n",
    "        tmp_dist = []\n",
    "        tmp_query = []\n",
    "        tmp_Co_occur = []\n",
    "        tmp_pair_occur = []\n",
    "\n",
    "        for m in range(0, len(query)):\n",
    "            tmp_dist.append(min_dist(query[m], term, doc_dict[doc_id].split()))\n",
    "            tmp_query.append(calc_freq([query[m]], doc_dict[doc_id].split(), 1))\n",
    "            tmp_Co_occur.append(calc_freq([query[m], term], doc_dict[doc_id].split(), 12))\n",
    "            for n in range(m+1, len(query)):\n",
    "                tmp_pair_occur.append(calc_freq([query[m], query[n], term], doc_dict[doc_id].split(), 15))\n",
    "\n",
    "        if not min_dist_all:\n",
    "            min_dist_all = tmp_dist[:]\n",
    "        else:\n",
    "            for i in range(0, len(min_dist_all)):\n",
    "                if min_dist_all[i] > tmp_dist[i]:\n",
    "                    min_dist_all[i] = tmp_dist[i]\n",
    "        term_fre_all.append(calc_freq([term], doc_dict[doc_id].split(), 1))\n",
    "        query_fre_all.append(tmp_query)\n",
    "        Co_occur_fre_all.append(tmp_Co_occur)\n",
    "        pair_occur_fre_all.append(tmp_pair_occur)\n",
    "\n",
    "        if doc_id in releDoc_ids:\n",
    "            if not min_dist_rele:\n",
    "                min_dist_rele = tmp_dist[:]\n",
    "            else:\n",
    "                for i in range(0, len(min_dist_rele)):\n",
    "                    if min_dist_rele[i] > tmp_dist[i]:\n",
    "                        min_dist_rele[i] = tmp_dist[i]\n",
    "            term_fre_rele.append(term_fre_all[-1])\n",
    "            query_fre_rele.append(query_fre_all[-1])\n",
    "            Co_occur_fre_rele.append(Co_occur_fre_all[-1])\n",
    "            pair_occur_fre_rele.append(pair_occur_fre_all[-1])\n",
    "\n",
    "    min_dist_all = np.array(min_dist_all)\n",
    "    term_fre_all = np.array(term_fre_all)\n",
    "    query_fre_all = np.array(query_fre_all)\n",
    "    Co_occur_fre_all = np.array(Co_occur_fre_all)\n",
    "    pair_occur_fre_all = np.array(pair_occur_fre_all)\n",
    "\n",
    "    min_dist_rele = np.array(min_dist_rele)\n",
    "    term_fre_rele = np.array(term_fre_rele)\n",
    "    query_fre_rele = np.array(query_fre_rele)\n",
    "    Co_occur_fre_rele = np.array(Co_occur_fre_rele)\n",
    "    pair_occur_fre_rele = np.array(pair_occur_fre_rele)\n",
    "\n",
    "    # Term distributions\n",
    "    features[0] = math.log(1 + term_fre_rele.sum() / query_fre_rele.sum(), 10)\n",
    "    features[1] = math.log(1 + term_fre_all.sum() / query_fre_all.sum(), 10)\n",
    "    # Co-occurrence with single query term\n",
    "    features[2] = math.log(1 + Co_occur_fre_rele.sum() / (len(query) * query_fre_rele.sum()), 10)\n",
    "    features[3] = math.log(1 + Co_occur_fre_all.sum() / (len(query) * query_fre_all.sum()), 10)\n",
    "    # Co-occurrence with pairs query terms\n",
    "    features[4] = math.log(1 + pair_occur_fre_rele.sum() / (pair_occur_fre_rele.shape[1] * query_fre_rele.sum() + 0.001), 10)\n",
    "    features[5] = math.log(1 + pair_occur_fre_all.sum() / (pair_occur_fre_all.shape[1] * query_fre_all.sum() + 0.001), 10)\n",
    "    # Weighted term proximity\n",
    "    features[6] = math.log(1 + np.sum(Co_occur_fre_rele.sum(axis=0) * min_dist_rele) / (Co_occur_fre_rele.sum() + 0.001), 10)\n",
    "    features[7] = math.log(1 + np.sum(Co_occur_fre_all.sum(axis=0) * min_dist_all) / (Co_occur_fre_all.sum() + 0.001), 10)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def mAP_differ(term, query_id, docIds, idf, mAP):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        term: str\n",
    "        query_id: str\n",
    "        docIds: str list\n",
    "        idf: float\n",
    "    Returns:\n",
    "        differ: float\n",
    "    \"\"\"\n",
    "    global query_dict, doc_dict, rele_dict\n",
    "\n",
    "    # calculate bm25 scores\n",
    "    docScore = dict()\n",
    "    for docId in docIds:\n",
    "        query = example_list2dict(query_dict[query_id] + ' ' + term)\n",
    "        doc = example_list2dict(doc_dict[docId])\n",
    "        docScore[docId] = bm25(query, doc, idf)\n",
    "      \n",
    "    # sort\n",
    "    labels = []\n",
    "    sort = sorted(docScore.items(), key=lambda item: item[1], reverse=True)\n",
    "    for i in range(0, len(docIds)):\n",
    "        labels.append(int(rele_dict[query_id][sort[i][0]]))\n",
    "    labels = np.array(labels)\n",
    "    # calc recall and precision\n",
    "    recall = []\n",
    "    precis = []\n",
    "    Tp_Fn = np.sum(labels)\n",
    "    for N in range(0, labels.shape[0]):\n",
    "        Tp_Fp = N + 1\n",
    "        Tp = np.sum(labels[0:N + 1])\n",
    "        recall.append(Tp / Tp_Fn)\n",
    "        precis.append(Tp / Tp_Fp)\n",
    "    recall = np.array(recall)\n",
    "    precis = np.array(precis)\n",
    "\n",
    "    mAP_expan = ave_prec(recall, precis, True)\n",
    "    differ = mAP_expan - mAP\n",
    "\n",
    "    return differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Current query ID: 50\n",
      "37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-137b501ccc9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mmAP_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmAP_differ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmAP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmAP_d\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_N\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-44ed674d12c6>\u001b[0m in \u001b[0;36mmAP_differ\u001b[1;34m(term, query_id, docIds, idf, mAP)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample_list2dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mterm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample_list2dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdocId\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mdocScore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdocId\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m# sort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-954261a25130>\u001b[0m in \u001b[0;36mbm25\u001b[1;34m(query, doc, idf, avg_doc_len)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mbm25\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_doc_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m374\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mk1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mk2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x = np.empty(shape=[0, 8])\n",
    "train_y = np.empty(shape=[0, 1])\n",
    "\n",
    "idf = cal_idf(doc_dict=doc_dict)\n",
    "\n",
    "for query_id in range(50, 249):\n",
    "    print('-----Current query ID: %d' % query_id)\n",
    "    # docs'ID corresponding to query_id\n",
    "    doc_ids = []\n",
    "    docs = []\n",
    "    for Id in range(0, 300):\n",
    "        st = '%s_%d' % (query_id, Id)\n",
    "        if doc_dict.get(st) is None:\n",
    "            break\n",
    "        else:\n",
    "            doc_ids.append(st)\n",
    "            docs.append(doc_dict[st].split())\n",
    "    \n",
    "    # calculate bm25 scores of docs\n",
    "    doc_score = dict()\n",
    "    query = example_list2dict(query_dict[str(query_id)])\n",
    "    for doc_id in doc_ids:\n",
    "        doc = example_list2dict(doc_dict[doc_id])\n",
    "        doc_score[doc_id] = bm25(query, doc, idf)\n",
    "\n",
    "    # sort and choose top N docs\n",
    "    # get the sorted label\n",
    "    N = 20\n",
    "    top_N = []\n",
    "    labels = []\n",
    "    sort = sorted(doc_score.items(), key=lambda item: item[1], reverse=True)\n",
    "    for i in range(0, len(doc_ids)):\n",
    "        if i < N:\n",
    "            top_N.append(sort[i][0])\n",
    "        labels.append(int(rele_dict[str(query_id)][sort[i][0]]))\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # calc recall and precision\n",
    "    recall = []\n",
    "    precis = []\n",
    "    Tp_Fn = np.sum(labels == 1)\n",
    "    for N in range(0, labels.shape[0]):\n",
    "        Tp_Fp = N + 1\n",
    "        Tp = np.sum(labels[0:N + 1] == 1)\n",
    "        recall.append(Tp / Tp_Fn)\n",
    "        precis.append(Tp / Tp_Fp)\n",
    "    recall = np.array(recall)\n",
    "    precis = np.array(precis)\n",
    "    # calc mean average precision\n",
    "    mAP = ave_prec(recall, precis)\n",
    "    # candidate expansion terms\n",
    "    candidate = []\n",
    "    for doc_id in top_N:\n",
    "        candidate.extend(doc_dict[doc_id].split())\n",
    "    candidate = list(set(candidate) - set(query_dict[str(query_id)].split()))\n",
    "\n",
    "    # features vector and label for each expansion term\n",
    "    X = []\n",
    "    for term in candidate:\n",
    "        mAP_d = mAP_differ(term, str(query_id), doc_ids, idf, mAP)\n",
    "        if mAP_d > 0.1:\n",
    "            X.append(get_feature(term, str(query_id), doc_ids, top_N))\n",
    "            train_y = np.append(train_y, [[1]], axis=0)\n",
    "        elif mAP_d < -0.1:\n",
    "            X.append(get_feature(term, str(query_id), doc_ids, top_N))\n",
    "            train_y = np.append(train_y, [[0]], axis=0)\n",
    "    X = np.array(X)\n",
    "    if X.shape[0] > 0:\n",
    "        X = normalize(X, axis=0, norm='max')\n",
    "        train_x = np.append(train_x, X, axis=0)\n",
    "# ------------------------------------------\n",
    "# save train data\n",
    "np.savetxt('E:/PycharmProjects/EE448/ee448-project2-query-expansion/train_x.txt', train_x)\n",
    "np.savetxt('E:/PycharmProjects/EE448/ee448-project2-query-expansion/train_y.txt', train_y)\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_x = np.loadtxt('E:/PycharmProjects/EE448/ee448-project2-query-expansion/train_x.txt')\n",
    "train_y = np.loadtxt('E:/PycharmProjects/EE448/ee448-project2-query-expansion/train_y.txt')\n",
    "\n",
    "train_y = train_y.astype(int)\n",
    "train_y.reshape(train_y.shape[0], 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.3)\n",
    "\n",
    "classifier = svm.SVC(C=10, kernel='rbf', gamma='auto', class_weight='balanced', probability=True)\n",
    "classifier.fit(train_x, train_y)\n",
    "\n",
    "print(\"train accuracy:\", classifier.score(x_train, y_train) )\n",
    "print(\"test  accuracy:\", classifier.score(x_test, y_test) )\n",
    "\n",
    "query_expan = dict()\n",
    "#idf = cal_idf(doc_dict=doc_dict)\n",
    "\n",
    "for query_id in range(0, 50):\n",
    "    print('-----Current query ID: %d' % query_id)\n",
    "\n",
    "    # docs'ID corresponding to query_id\n",
    "    doc_ids = []\n",
    "    for Id in range(0, 300):\n",
    "        st = '%s_%d' % (query_id, Id)\n",
    "        if doc_dict.get(st) is None:\n",
    "            break\n",
    "        else:\n",
    "            doc_ids.append(st)\n",
    "    \n",
    "    # calculate bm25 scores of docs\n",
    "    doc_score = dict()\n",
    "    query = example_list2dict(query_dict[str(query_id)])\n",
    "    for doc_id in doc_ids:\n",
    "        doc = example_list2dict(doc_dict[doc_id])\n",
    "        doc_score[doc_id] = bm25(query, doc, idf)\n",
    "        \n",
    "    # sort and choose top N docs\n",
    "    N = 20\n",
    "    top_N = []\n",
    "    sort = sorted(doc_score.items(), key=lambda item: item[1], reverse=True)\n",
    "    for i in range(0, N):\n",
    "        top_N.append(sort[i][0])\n",
    "\n",
    "    # candidate expansion terms\n",
    "    candidate = []\n",
    "    for doc_id in top_N:\n",
    "        candidate.extend(top_tfidf(doc_dict[doc_id].split(), 20))\n",
    "    candidate = list(set(candidate) - set(query_dict[str(query_id)].split()))\n",
    "    candidate.sort()\n",
    "    \n",
    "    features = []\n",
    "    for term in candidate:\n",
    "        feature = get_feature(term, str(query_id), doc_ids, top_N)\n",
    "        features.append(feature)\n",
    "        \n",
    "    features = np.array(features)\n",
    "    features = normalize(features, axis=0, norm='max')\n",
    "    pred = classifier.predict_proba(features)\n",
    "    \n",
    "    labels = dict()\n",
    "    n = 0\n",
    "    for label in pred:\n",
    "        if label[1] > 0.6:\n",
    "            labels[candidate[n]] = label[1]\n",
    "        n += 1\n",
    "           \n",
    "    label_sort = sorted(labels.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    tmp = ''\n",
    "    count = 20\n",
    "    for item in label_sort:\n",
    "        if count == 0:\n",
    "            break\n",
    "        if tmp == '':\n",
    "            tmp += item[0]\n",
    "        else:\n",
    "            tmp = tmp + ' ' + item[0]\n",
    "        count -= 1\n",
    "        \n",
    "    query_expan[str(query_id)] = tmp\n",
    "\n",
    "# ------------------------------------------\n",
    "# save expanded query\n",
    "file_handle = open( 'E:/PycharmProjects/EE448/ee448-project2-query-expansion/query_e.txt', mode='w')\n",
    "for query_id in range(0, 50):\n",
    "    file_handle.write(str(query_id)+'\\t'+query_dict[str(query_id)]+' '+query_expan[str(query_id)]+'\\n')\n",
    "file_handle.close()\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
